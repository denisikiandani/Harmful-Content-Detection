{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcad2990-9cd0-4604-bec2-5319872b4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitasi Synchronous:\n",
    "# ---------------------------------\n",
    "# Audio Maximum 1 Menit\n",
    "# Audio Maximum 10 MB\n",
    "# ---------------------------------\n",
    "\n",
    "# Import Library\n",
    "from google.cloud.speech_v2 import SpeechClient\n",
    "from google.cloud.speech_v2.types import cloud_speech\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Function transkrip audio Synchronous\n",
    "def transcribe_file_v2(project_id: str, audio_file: str) -> cloud_speech.RecognizeResponse:\n",
    "    # Instantiates client\n",
    "    credentials = service_account.Credentials.from_service_account_file('gcloud_apikey.json')\n",
    "    client = SpeechClient(credentials=credentials)\n",
    "\n",
    "    # Baca file dalam bytes\n",
    "    with open(audio_file, \"rb\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Config untuk speech recognition\n",
    "    config = cloud_speech.RecognitionConfig(\n",
    "        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),\n",
    "        language_codes=[\"en-US\"],\n",
    "        model=\"long\",\n",
    "    )\n",
    "\n",
    "    # Membentuk objek request\n",
    "    request = cloud_speech.RecognizeRequest(\n",
    "        recognizer=f\"projects/{project_id}/locations/global/recognizers/_\",\n",
    "        config=config,\n",
    "        content=content,\n",
    "    )\n",
    "\n",
    "    # Transkrip audio menjadi teks\n",
    "    response = client.recognize(request=request)\n",
    "\n",
    "    # Print respon transkrip\n",
    "    for result in response.results:\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "\n",
    "    # Return respon transkrip\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a46d1a-45ab-4a4e-8106-c8951307feb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"500\" controls>\n",
       "    <source src=\"speech_data/Anime.mp4\" type=\"video/mp4\">\n",
       "    <track src=\"Anime.srt\" kind=\"subtitles\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"500\" controls>\n",
    "    <source src=\"speech_data/Anime.mp4\" type=\"video/mp4\">\n",
    "    <track src=\"Anime.srt\" kind=\"subtitles\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3f8b85-c915-4e99-bb76-576f06e98cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in speech_data/Anime.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Deklarasi input dan output\n",
    "mp4_file = \"speech_data/Anime.mp4\"\n",
    "mp3_file = \"speech_data/Anime.mp3\"\n",
    "\n",
    "# Load video\n",
    "video_clip = VideoFileClip(mp4_file)\n",
    "\n",
    "# Ekstrak audio dari video\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Simpan audio ke file\n",
    "audio_clip.write_audiofile(mp3_file)\n",
    "\n",
    "# Menutup file audio dan video\n",
    "audio_clip.close()\n",
    "video_clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe418f9-74ca-4ce1-b9e0-96fe8d034a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "Transcript:  it's really embarrassed me\n",
      "Transcript:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "Transcript:  what if I told you in person just leave me alone didn't you hear me\n",
      "Transcript:  but I hate you\n",
      "Transcript:  I see\n",
      "Transcript:  you hate me that much okay well then\n",
      "Transcript:  hey\n"
     ]
    }
   ],
   "source": [
    "## Menyimpan Hasil Transkrip\n",
    "hasil_transkrip = transcribe_file_v2(\n",
    "    project_id='data-science-programming-ti24',\n",
    "    audio_file='speech_data/Anime.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bebce569-2b48-468b-bc3a-c1c24c747dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"she know that I I just wanted to cheer you see we you and I are the same I can\\'t say the things that I truly feel just stop it and you\\'re wrong we\\'re nothing alike\"\n",
      "    confidence: 0.877077401\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 13\n",
      "    nanos: 880000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" it\\'s really embarrassed me\"\n",
      "    confidence: 0.944916487\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 17\n",
      "    nanos: 140000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\"\n",
      "    confidence: 0.959103167\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 25\n",
      "    nanos: 920000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" what if I told you in person just leave me alone didn\\'t you hear me\"\n",
      "    confidence: 0.890649438\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 31\n",
      "    nanos: 460000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" but I hate you\"\n",
      "    confidence: 0.813417912\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 33\n",
      "    nanos: 420000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" I see\"\n",
      "    confidence: 0.654533\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 45\n",
      "    nanos: 130000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" you hate me that much okay well then\"\n",
      "    confidence: 0.841478825\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 54\n",
      "    nanos: 560000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" hey\"\n",
      "    confidence: 0.344252855\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 57\n",
      "    nanos: 170000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "metadata {\n",
      "  total_billed_duration {\n",
      "    seconds: 60\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hasil_transkrip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857cf45b-cd61-4f0b-bb80-d6bfeb0c1dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\",\n",
       " \" it's really embarrassed me\",\n",
       " ' have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you',\n",
       " \" what if I told you in person just leave me alone didn't you hear me\",\n",
       " ' but I hate you',\n",
       " ' I see',\n",
       " ' you hate me that much okay well then',\n",
       " ' hey']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_hasil_transkrip = list()\n",
    "\n",
    "for hasil in hasil_transkrip.results:\n",
    "    teks = f'{hasil.alternatives[0].transcript}'\n",
    "    list_hasil_transkrip.append(teks)\n",
    "\n",
    "list_hasil_transkrip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa7301-ad9f-474d-b616-0534c6b9f782",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc60f715-0b94-439e-a891-b88b1a0176d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization #tokenization|\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11e3bc80-c854-45a9-918f-7974188cfa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('toxic-v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be7fc4d9-4acc-49e9-ae73-c4172862bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'sangat_toxic', 'cabul', 'ancaman', 'menyinggung', 'penghinaan']\n",
    "# toxic == toxic\n",
    "# sever_toxic == toxic_parah\n",
    "# obscene == cabul\n",
    "# threat == ancaman\n",
    "# insult == menyinggung \n",
    "# indentity_hate == benci personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e11ac4e-2868-4c3d-8d3a-26a3f9bd9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer_config.pkl', 'rb') as f:\n",
    "    vectorizer_config = pickle.load(f)\n",
    "with open('vectorizer_vocab.pkl', 'rb') as f:\n",
    "    vectorizer_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d55a4118-427f-42f7-99e0-a14fd0099e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization.from_config(vectorizer_config)\n",
    "vectorizer.set_vocabulary(vectorizer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a393978-013b-449e-8eea-87b60a12370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = list_hasil_transkrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d62342c-03dc-4cbe-92f8-ae658e3e9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each input text in the list\n",
    "vectorized_texts = [vectorizer(text) for text in input_data]\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "padded_texts = tf.keras.preprocessing.sequence.pad_sequences(vectorized_texts, maxlen=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7f78b3d-6ea9-4c72-8eff-98f9733f4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(padded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3abeef17-e35c-43f9-82c2-684ba7013bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d0c5005-9753-41ab-b726-e02f850985ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "toxic: 1\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  it's really embarrassed me\n",
      "toxic: 0\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "toxic: 1\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  what if I told you in person just leave me alone didn't you hear me\n",
      "toxic: 0\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  but I hate you\n",
      "toxic: 1\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  I see\n",
      "toxic: 0\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  you hate me that much okay well then\n",
      "toxic: 0\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n",
      "Text:  hey\n",
      "toxic: 0\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print predictions\n",
    "for i, text in enumerate(input_data):\n",
    "    print(\"Text:\", text)\n",
    "    for label, pred in zip(labels, binary_predictions[i]):\n",
    "        print(f\"{label}: {pred}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d7db5c-906f-434a-9a24-09449e8cb33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_predictions = binary_predictions.sum(axis=0)\n",
    "total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43182172-3873-4573-af0c-caf6f8915693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 3\n",
      "sangat_toxic: 0\n",
      "cabul: 0\n",
      "ancaman: 0\n",
      "menyinggung: 0\n",
      "penghinaan: 0\n"
     ]
    }
   ],
   "source": [
    "for i, (label, total) in enumerate(zip(labels, total_predictions)):\n",
    "    print(f\"{label}: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8821f752-c7cf-4d73-ad99-43239cfefaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "Prediction: toxic Value: 0.7711834907531738\n",
      "\n",
      "\n",
      "Text:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "Prediction: toxic Value: 0.7438677549362183\n",
      "\n",
      "\n",
      "Text:  but I hate you\n",
      "Prediction: toxic Value: 0.7965867519378662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total toxic predictions: 3\n",
      "Index Kalimat yang terdeteksi toxic: [0, 2, 4]\n",
      "\n",
      "Total sangat_toxic predictions: 0\n",
      "Index Kalimat yang terdeteksi sangat_toxic: []\n",
      "\n",
      "Total cabul predictions: 0\n",
      "Index Kalimat yang terdeteksi cabul: []\n",
      "\n",
      "Total ancaman predictions: 0\n",
      "Index Kalimat yang terdeteksi ancaman: []\n",
      "\n",
      "Total menyinggung predictions: 0\n",
      "Index Kalimat yang terdeteksi menyinggung: []\n",
      "\n",
      "Total penghinaan predictions: 0\n",
      "Index Kalimat yang terdeteksi penghinaan: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_index = {label: [] for label in labels}\n",
    "\n",
    "total_predictions = binary_predictions.sum(axis=0)\n",
    "\n",
    "for i, (prediction, text) in enumerate(zip(binary_predictions, input_data)):\n",
    "    # print(f\"Text: {text}\")\n",
    "    for j, (label, pred) in enumerate(zip(labels, prediction)):\n",
    "        if pred == 1:\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Prediction: {label} Value: {predictions[i][j]}\")\n",
    "            label_index[label].append(i)  # Store the index where the label was predicted as 1\n",
    "    print()\n",
    "\n",
    "for label, total in zip(labels, total_predictions):\n",
    "    print(f\"Total {label} predictions: {total}\")\n",
    "    print(f\"Index Kalimat yang terdeteksi {label}: {label_index[label]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e0e2f-9540-44f8-8a94-8a581728d56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040092c3-6a4a-42f3-af57-d6f492520610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
