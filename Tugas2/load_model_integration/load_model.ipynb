{
 "cells": [
  {
   "cell_type": "code",
   "id": "fcad2990-9cd0-4604-bec2-5319872b4273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:02:29.965440Z",
     "start_time": "2024-05-15T03:02:29.585186Z"
    }
   },
   "source": [
    "# Limitasi Synchronous:\n",
    "# ---------------------------------\n",
    "# Audio Maximum 1 Menit\n",
    "# Audio Maximum 10 MB\n",
    "# ---------------------------------\n",
    "\n",
    "# Import Library\n",
    "from google.cloud.speech_v2 import SpeechClient\n",
    "from google.cloud.speech_v2.types import cloud_speech\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Function transkrip audio Synchronous\n",
    "def transcribe_file_v2(project_id: str, audio_file: str) -> cloud_speech.RecognizeResponse:\n",
    "    # Instantiates client\n",
    "    credentials = service_account.Credentials.from_service_account_file('gcloud_apikey.json')\n",
    "    client = SpeechClient(credentials=credentials)\n",
    "\n",
    "    # Baca file dalam bytes\n",
    "    with open(audio_file, \"rb\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Config untuk speech recognition\n",
    "    config = cloud_speech.RecognitionConfig(\n",
    "        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),\n",
    "        language_codes=[\"en-US\"],\n",
    "        model=\"long\",\n",
    "    )\n",
    "\n",
    "    # Membentuk objek request\n",
    "    request = cloud_speech.RecognizeRequest(\n",
    "        recognizer=f\"projects/{project_id}/locations/global/recognizers/_\",\n",
    "        config=config,\n",
    "        content=content,\n",
    "    )\n",
    "\n",
    "    # Transkrip audio menjadi teks\n",
    "    response = client.recognize(request=request)\n",
    "\n",
    "    # Print respon transkrip\n",
    "    for result in response.results:\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "\n",
    "    # Return respon transkrip\n",
    "    return response"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "84a46d1a-45ab-4a4e-8106-c8951307feb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:02:30.950842Z",
     "start_time": "2024-05-15T03:02:30.943323Z"
    }
   },
   "source": [
    "%%HTML\n",
    "<video width=\"500\" controls>\n",
    "    <source src=\"speech_data/Anime.mp4\" type=\"video/mp4\">\n",
    "    <track src=\"Anime.srt\" kind=\"subtitles\">\n",
    "</video>"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<video width=\"500\" controls>\n",
       "    <source src=\"speech_data/Anime.mp4\" type=\"video/mp4\">\n",
       "    <track src=\"Anime.srt\" kind=\"subtitles\">\n",
       "</video>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7e3f8b85-c915-4e99-bb76-576f06e98cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:02:35.554978Z",
     "start_time": "2024-05-15T03:02:32.276994Z"
    }
   },
   "source": [
    "# Import Library\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Deklarasi input dan output\n",
    "mp4_file = \"speech_data/Anime.mp4\"\n",
    "mp3_file = \"speech_data/Anime.mp3\"\n",
    "\n",
    "# Load video\n",
    "video_clip = VideoFileClip(mp4_file)\n",
    "\n",
    "# Ekstrak audio dari video\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Simpan audio ke file\n",
    "audio_clip.write_audiofile(mp3_file)\n",
    "\n",
    "# Menutup file audio dan video\n",
    "audio_clip.close()\n",
    "video_clip.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in speech_data/Anime.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4fe418f9-74ca-4ce1-b9e0-96fe8d034a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:02:53.558557Z",
     "start_time": "2024-05-15T03:02:41.829102Z"
    }
   },
   "source": [
    "## Menyimpan Hasil Transkrip\n",
    "hasil_transkrip = transcribe_file_v2(\n",
    "    project_id='data-science-programming-ti24',\n",
    "    audio_file='speech_data/Anime.mp3')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "Transcript:  it's really embarrassed me\n",
      "Transcript:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "Transcript:  what if I told you in person just leave me alone didn't you hear me\n",
      "Transcript:  but I hate you\n",
      "Transcript:  I see\n",
      "Transcript:  you hate me that much okay well then\n",
      "Transcript:  hey\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "bebce569-2b48-468b-bc3a-c1c24c747dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:03:37.360005Z",
     "start_time": "2024-05-15T03:03:37.354814Z"
    }
   },
   "source": [
    "print(hasil_transkrip)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"she know that I I just wanted to cheer you see we you and I are the same I can\\'t say the things that I truly feel just stop it and you\\'re wrong we\\'re nothing alike\"\n",
      "    confidence: 0.876547933\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 13\n",
      "    nanos: 880000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" it\\'s really embarrassed me\"\n",
      "    confidence: 0.944364965\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 17\n",
      "    nanos: 140000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\"\n",
      "    confidence: 0.959146261\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 25\n",
      "    nanos: 920000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" what if I told you in person just leave me alone didn\\'t you hear me\"\n",
      "    confidence: 0.888463736\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 31\n",
      "    nanos: 460000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" but I hate you\"\n",
      "    confidence: 0.815426528\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 33\n",
      "    nanos: 420000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" I see\"\n",
      "    confidence: 0.658186555\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 45\n",
      "    nanos: 130000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" you hate me that much okay well then\"\n",
      "    confidence: 0.841749549\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 54\n",
      "    nanos: 560000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" hey\"\n",
      "    confidence: 0.341029823\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 57\n",
      "    nanos: 170000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "metadata {\n",
      "  total_billed_duration {\n",
      "    seconds: 60\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "857cf45b-cd61-4f0b-bb80-d6bfeb0c1dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:03:39.397838Z",
     "start_time": "2024-05-15T03:03:39.392530Z"
    }
   },
   "source": [
    "list_hasil_transkrip = list()\n",
    "\n",
    "for hasil in hasil_transkrip.results:\n",
    "    teks = f'{hasil.alternatives[0].transcript}'\n",
    "    list_hasil_transkrip.append(teks)\n",
    "\n",
    "list_hasil_transkrip"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\",\n",
       " \" it's really embarrassed me\",\n",
       " ' have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you',\n",
       " \" what if I told you in person just leave me alone didn't you hear me\",\n",
       " ' but I hate you',\n",
       " ' I see',\n",
       " ' you hate me that much okay well then',\n",
       " ' hey']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "05fa7301-ad9f-474d-b616-0534c6b9f782",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc60f715-0b94-439e-a891-b88b1a0176d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:03:47.008471Z",
     "start_time": "2024-05-15T03:03:41.880825Z"
    }
   },
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization #tokenization|\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "11e3bc80-c854-45a9-918f-7974188cfa0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:05:04.412684Z",
     "start_time": "2024-05-15T03:05:03.837364Z"
    }
   },
   "source": [
    "model = tf.keras.models.load_model('toxic-v1.h5')"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weight count mismatch for layer #1 (named bidirectional in the current model, bidirectional in the save file). Layer expects 9 weight(s). Received 6 saved weight(s)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtoxic-v1.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\scoop\\apps\\python311\\current\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[0;32m    177\u001B[0m         filepath,\n\u001B[0;32m    178\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[0;32m    179\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[0;32m    180\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[0;32m    181\u001B[0m     )\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[1;32m--> 183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_h5_format\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model_from_hdf5\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    186\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile not found: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    187\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease ensure the file is an accessible `.keras` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    188\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzip file.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    189\u001B[0m     )\n",
      "File \u001B[1;32m~\\scoop\\apps\\python311\\current\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:138\u001B[0m, in \u001B[0;36mload_model_from_hdf5\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    133\u001B[0m     model \u001B[38;5;241m=\u001B[39m saving_utils\u001B[38;5;241m.\u001B[39mmodel_from_config(\n\u001B[0;32m    134\u001B[0m         model_config, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects\n\u001B[0;32m    135\u001B[0m     )\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# set weights\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[43mload_weights_from_hdf5_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_weights\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcompile\u001B[39m:\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;66;03m# instantiate optimizer\u001B[39;00m\n\u001B[0;32m    142\u001B[0m     training_config \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mattrs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_config\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\scoop\\apps\\python311\\current\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:369\u001B[0m, in \u001B[0;36mload_weights_from_hdf5_group\u001B[1;34m(f, model)\u001B[0m\n\u001B[0;32m    367\u001B[0m weight_values \u001B[38;5;241m=\u001B[39m load_subset_weights_from_hdf5_group(g)\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(weight_values) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(symbolic_weights):\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    370\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWeight count mismatch for layer #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe current model, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in the save file). \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    372\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLayer expects \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(symbolic_weights)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m weight(s). Received \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    373\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(weight_values)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m saved weight(s)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    374\u001B[0m     )\n\u001B[0;32m    375\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ref_v, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(symbolic_weights, weight_values):\n\u001B[0;32m    376\u001B[0m     ref_v\u001B[38;5;241m.\u001B[39massign(val)\n",
      "\u001B[1;31mValueError\u001B[0m: Weight count mismatch for layer #1 (named bidirectional in the current model, bidirectional in the save file). Layer expects 9 weight(s). Received 6 saved weight(s)"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "be7fc4d9-4acc-49e9-ae73-c4172862bc89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:04:02.925644Z",
     "start_time": "2024-05-15T03:04:02.921639Z"
    }
   },
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# toxic == toxic\n",
    "# sever_toxic == toxic_parah\n",
    "# obscene == cabul\n",
    "# threat == ancaman\n",
    "# insult == menyinggung \n",
    "# indentity_hate == benci personal"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "0e11ac4e-2868-4c3d-8d3a-26a3f9bd9c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:04:04.665853Z",
     "start_time": "2024-05-15T03:04:03.530035Z"
    }
   },
   "source": [
    "with open('vectorizer_config.pkl', 'rb') as f:\n",
    "    vectorizer_config = pickle.load(f)\n",
    "with open('vectorizer_vocab.pkl', 'rb') as f:\n",
    "    vectorizer_vocab = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d55a4118-427f-42f7-99e0-a14fd0099e3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:04:47.889052Z",
     "start_time": "2024-05-15T03:04:12.513825Z"
    }
   },
   "source": [
    "vectorizer = TextVectorization.from_config(vectorizer_config)\n",
    "vectorizer.set_vocabulary(vectorizer_vocab)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3870f9fc-868c-4503-8d45-57b7be9de066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))\n",
    "# X = df['comment_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a369ce4d-b3a8-464d-87a7-d4b40b907723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['threat']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a944361c-5cf3-4532-9364-78a1ab5e5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_FEATURES = 200000\n",
    "# vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=1800, output_mode='int')\n",
    "# vectorizer.adapt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a41ecf-8853-4d28-a9fc-27c433f139c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.set_vocabulary(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a393978-013b-449e-8eea-87b60a12370f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:04:56.387951Z",
     "start_time": "2024-05-15T03:04:56.379803Z"
    }
   },
   "source": [
    "input_data = list_hasil_transkrip"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "0d62342c-03dc-4cbe-92f8-ae658e3e9680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:04:57.547963Z",
     "start_time": "2024-05-15T03:04:56.836418Z"
    }
   },
   "source": [
    "# Vectorize each input text in the list\n",
    "vectorized_texts = [vectorizer(text) for text in input_data]\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "padded_texts = tf.keras.preprocessing.sequence.pad_sequences(vectorized_texts, maxlen=1800)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "d7f78b3d-6ea9-4c72-8eff-98f9733f4de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T03:04:59.490490Z",
     "start_time": "2024-05-15T03:04:59.182785Z"
    }
   },
   "source": [
    "predictions = model.predict(padded_texts)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(padded_texts)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3abeef17-e35c-43f9-82c2-684ba7013bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d0c5005-9753-41ab-b726-e02f850985ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  it's really embarrassed me\n",
      "toxic: 0\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  what if I told you in person just leave me alone didn't you hear me\n",
      "toxic: 0\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  but I hate you\n",
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  I see\n",
      "toxic: 0\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  you hate me that much okay well then\n",
      "toxic: 0\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n",
      "Text:  hey\n",
      "toxic: 0\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print predictions\n",
    "for i, text in enumerate(input_data):\n",
    "    print(\"Text:\", text)\n",
    "    for label, pred in zip(labels, binary_predictions[i]):\n",
    "        print(f\"{label}: {pred}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d7db5c-906f-434a-9a24-09449e8cb33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_predictions = binary_predictions.sum(axis=0)\n",
    "total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43182172-3873-4573-af0c-caf6f8915693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 3\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n"
     ]
    }
   ],
   "source": [
    "for i, (label, total) in enumerate(zip(labels, total_predictions)):\n",
    "    print(f\"{label}: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8821f752-c7cf-4d73-ad99-43239cfefaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "Prediction: toxic Value: 0.7711834907531738\n",
      "\n",
      "\n",
      "Text:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "Prediction: toxic Value: 0.7438677549362183\n",
      "\n",
      "\n",
      "Text:  but I hate you\n",
      "Prediction: toxic Value: 0.7965867519378662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total toxic predictions: 3\n",
      "Index Kalimat yang terdeteksi toxic: [0, 2, 4]\n",
      "\n",
      "Total severe_toxic predictions: 0\n",
      "Index Kalimat yang terdeteksi severe_toxic: []\n",
      "\n",
      "Total obscene predictions: 0\n",
      "Index Kalimat yang terdeteksi obscene: []\n",
      "\n",
      "Total threat predictions: 0\n",
      "Index Kalimat yang terdeteksi threat: []\n",
      "\n",
      "Total insult predictions: 0\n",
      "Index Kalimat yang terdeteksi insult: []\n",
      "\n",
      "Total identity_hate predictions: 0\n",
      "Index Kalimat yang terdeteksi identity_hate: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_index = {label: [] for label in labels}\n",
    "\n",
    "total_predictions = binary_predictions.sum(axis=0)\n",
    "\n",
    "for i, (prediction, text) in enumerate(zip(binary_predictions, input_data)):\n",
    "    # print(f\"Text: {text}\")\n",
    "    for j, (label, pred) in enumerate(zip(labels, prediction)):\n",
    "        if pred == 1:\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Prediction: {label} Value: {predictions[i][j]}\")\n",
    "            label_index[label].append(i)  # Store the index where the label was predicted as 1\n",
    "    print()\n",
    "\n",
    "for label, total in zip(labels, total_predictions):\n",
    "    print(f\"Total {label} predictions: {total}\")\n",
    "    print(f\"Index Kalimat yang terdeteksi {label}: {label_index[label]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e0e2f-9540-44f8-8a94-8a581728d56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9f28f-bd2f-4345-b64a-514582ddadb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
