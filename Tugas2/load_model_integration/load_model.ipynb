{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcad2990-9cd0-4604-bec2-5319872b4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitasi Synchronous:\n",
    "# ---------------------------------\n",
    "# Audio Maximum 1 Menit\n",
    "# Audio Maximum 10 MB\n",
    "# ---------------------------------\n",
    "\n",
    "# Import Library\n",
    "from google.cloud.speech_v2 import SpeechClient\n",
    "from google.cloud.speech_v2.types import cloud_speech\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "# Function transkrip audio Synchronous\n",
    "def transcribe_file_v2(project_id: str, audio_file: str) -> cloud_speech.RecognizeResponse:\n",
    "    # Instantiates client\n",
    "    credentials = service_account.Credentials.from_service_account_file('gcloud_apikey.json')\n",
    "    client = SpeechClient(credentials=credentials)\n",
    "\n",
    "    # Baca file dalam bytes\n",
    "    with open(audio_file, \"rb\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Config untuk speech recognition\n",
    "    config = cloud_speech.RecognitionConfig(\n",
    "        auto_decoding_config=cloud_speech.AutoDetectDecodingConfig(),\n",
    "        language_codes=[\"en-US\"],\n",
    "        model=\"long\",\n",
    "    )\n",
    "\n",
    "    # Membentuk objek request\n",
    "    request = cloud_speech.RecognizeRequest(\n",
    "        recognizer=f\"projects/{project_id}/locations/global/recognizers/_\",\n",
    "        config=config,\n",
    "        content=content,\n",
    "    )\n",
    "\n",
    "    # Transkrip audio menjadi teks\n",
    "    response = client.recognize(request=request)\n",
    "\n",
    "    # Print respon transkrip\n",
    "    for result in response.results:\n",
    "        print(f\"Transcript: {result.alternatives[0].transcript}\")\n",
    "\n",
    "    # Return respon transkrip\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a46d1a-45ab-4a4e-8106-c8951307feb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"500\" controls>\n",
       "    <source src=\"speech_data/Anime.mp4\" type=\"video/mp4\">\n",
       "    <track src=\"Anime.srt\" kind=\"subtitles\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"500\" controls>\n",
    "    <source src=\"speech_data/Anime.mp4\" type=\"video/mp4\">\n",
    "    <track src=\"Anime.srt\" kind=\"subtitles\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3f8b85-c915-4e99-bb76-576f06e98cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in speech_data/Anime.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Deklarasi input dan output\n",
    "mp4_file = \"speech_data/Anime.mp4\"\n",
    "mp3_file = \"speech_data/Anime.mp3\"\n",
    "\n",
    "# Load video\n",
    "video_clip = VideoFileClip(mp4_file)\n",
    "\n",
    "# Ekstrak audio dari video\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Simpan audio ke file\n",
    "audio_clip.write_audiofile(mp3_file)\n",
    "\n",
    "# Menutup file audio dan video\n",
    "audio_clip.close()\n",
    "video_clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe418f9-74ca-4ce1-b9e0-96fe8d034a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\n",
      "Transcript:  it's really embarrassed me\n",
      "Transcript:  have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\n",
      "Transcript:  what if I told you in person just leave me alone didn't you hear me\n",
      "Transcript:  but I hate you\n",
      "Transcript:  I see\n",
      "Transcript:  you hate me that much okay well then\n",
      "Transcript:  hey\n"
     ]
    }
   ],
   "source": [
    "## Menyimpan Hasil Transkrip\n",
    "hasil_transkrip = transcribe_file_v2(\n",
    "    project_id='data-science-programming-ti24',\n",
    "    audio_file='speech_data/Anime.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebce569-2b48-468b-bc3a-c1c24c747dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"she know that I I just wanted to cheer you see we you and I are the same I can\\'t say the things that I truly feel just stop it and you\\'re wrong we\\'re nothing alike\"\n",
      "    confidence: 0.877077341\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 13\n",
      "    nanos: 880000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" it\\'s really embarrassed me\"\n",
      "    confidence: 0.944916487\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 17\n",
      "    nanos: 140000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you\"\n",
      "    confidence: 0.959103167\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 25\n",
      "    nanos: 920000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" what if I told you in person just leave me alone didn\\'t you hear me\"\n",
      "    confidence: 0.890649498\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 31\n",
      "    nanos: 460000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" but I hate you\"\n",
      "    confidence: 0.813417912\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 33\n",
      "    nanos: 420000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" I see\"\n",
      "    confidence: 0.654533\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 45\n",
      "    nanos: 130000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" you hate me that much okay well then\"\n",
      "    confidence: 0.841478944\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 54\n",
      "    nanos: 560000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \" hey\"\n",
      "    confidence: 0.344252914\n",
      "  }\n",
      "  result_end_offset {\n",
      "    seconds: 57\n",
      "    nanos: 170000000\n",
      "  }\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "metadata {\n",
      "  total_billed_duration {\n",
      "    seconds: 60\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hasil_transkrip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857cf45b-cd61-4f0b-bb80-d6bfeb0c1dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"she know that I I just wanted to cheer you see we you and I are the same I can't say the things that I truly feel just stop it and you're wrong we're nothing alike\",\n",
       " \" it's really embarrassed me\",\n",
       " ' have you considered my feelings at all everyone just hurt this I seriously hate pushy people like you',\n",
       " \" what if I told you in person just leave me alone didn't you hear me\",\n",
       " ' but I hate you',\n",
       " ' I see',\n",
       " ' you hate me that much okay well then',\n",
       " ' hey']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_hasil_transkrip = list()\n",
    "\n",
    "for hasil in hasil_transkrip.results:\n",
    "    teks = f'{hasil.alternatives[0].transcript}'\n",
    "    list_hasil_transkrip.append(teks)\n",
    "\n",
    "list_hasil_transkrip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa7301-ad9f-474d-b616-0534c6b9f782",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc60f715-0b94-439e-a891-b88b1a0176d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization #tokenization|\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e3bc80-c854-45a9-918f-7974188cfa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('toxic-v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7fc4d9-4acc-49e9-ae73-c4172862bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# toxic == toxic\n",
    "# sever_toxic == toxic_parah\n",
    "# obscene == cabul\n",
    "# threat == ancaman\n",
    "# insult == menyinggung \n",
    "# indentity_hate == benci personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e11ac4e-2868-4c3d-8d3a-26a3f9bd9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer_config.pkl', 'rb') as f:\n",
    "    vectorizer_config = pickle.load(f)\n",
    "with open('vectorizer_vocab.pkl', 'rb') as f:\n",
    "    vectorizer_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d55a4118-427f-42f7-99e0-a14fd0099e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization.from_config(vectorizer_config)\n",
    "vectorizer.set_vocabulary(vectorizer_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3870f9fc-868c-4503-8d45-57b7be9de066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))\n",
    "# X = df['comment_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a369ce4d-b3a8-464d-87a7-d4b40b907723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['threat']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a944361c-5cf3-4532-9364-78a1ab5e5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_FEATURES = 200000\n",
    "# vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=1800, output_mode='int')\n",
    "# vectorizer.adapt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a41ecf-8853-4d28-a9fc-27c433f139c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.set_vocabulary(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a393978-013b-449e-8eea-87b60a12370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = list_hasil_transkrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d62342c-03dc-4cbe-92f8-ae658e3e9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each input text in the list\n",
    "vectorized_texts = [vectorizer(text) for text in input_data]\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "padded_texts = tf.keras.preprocessing.sequence.pad_sequences(vectorized_texts, maxlen=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f78b3d-6ea9-4c72-8eff-98f9733f4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(padded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abeef17-e35c-43f9-82c2-684ba7013bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c5005-9753-41ab-b726-e02f850985ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predictions\n",
    "for i, text in enumerate(input_data):\n",
    "    print(\"Text:\", text)\n",
    "    for label, pred in zip(labels, binary_predictions[i]):\n",
    "        print(f\"{label}: {pred}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7db5c-906f-434a-9a24-09449e8cb33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predictions = binary_predictions.sum(axis=0)\n",
    "total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43182172-3873-4573-af0c-caf6f8915693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (label, total) in enumerate(zip(labels, total_predictions)):\n",
    "    print(f\"{label}: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821f752-c7cf-4d73-ad99-43239cfefaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = {label: [] for label in labels}\n",
    "\n",
    "total_predictions = binary_predictions.sum(axis=0)\n",
    "\n",
    "for i, (prediction, text) in enumerate(zip(binary_predictions, input_data)):\n",
    "    # print(f\"Text: {text}\")\n",
    "    for j, (label, pred) in enumerate(zip(labels, prediction)):\n",
    "        if pred == 1:\n",
    "            print(f\"Text: {text}\")\n",
    "            print(f\"Prediction: {label} Value: {predictions[i][j]}\")\n",
    "            label_index[label].append(i)  # Store the index where the label was predicted as 1\n",
    "    print()\n",
    "\n",
    "for label, total in zip(labels, total_predictions):\n",
    "    print(f\"Total {label} predictions: {total}\")\n",
    "    print(f\"Index Kalimat yang terdeteksi {label}: {label_index[label]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e0e2f-9540-44f8-8a94-8a581728d56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9f28f-bd2f-4345-b64a-514582ddadb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a74c25-b05f-4bfd-ac23-c0128918c689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071fc06-9cbe-46b0-a062-8b4cb55bb2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6cab2d-1578-4473-ab7a-197a59992021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b4dad5e-a5f0-46fc-aee4-d5fb1a39c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer(coba_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "788b418f-6d30-40db-aaaa-3f28e186cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 547ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d99a71b-6732-4941-83e8-13d398ff9b1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8127243 , 0.03915123, 0.4758387 , 0.04838365, 0.45078787,\n",
       "        0.08074123]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78e4d0f8-24b2-41f0-994f-2407e293fccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_prediction = (prediction > 0.5).astype(int)\n",
    "binary_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d888a1db-20db-46fa-aec5-04e1b75f0afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic: 1\n",
      "severe_toxic: 0\n",
      "obscene: 0\n",
      "threat: 0\n",
      "insult: 0\n",
      "identity_hate: 0\n"
     ]
    }
   ],
   "source": [
    "for label, pred in zip(labels, binary_prediction[0]):\n",
    "    print(f\"{label}: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e77d76c6-7ae1-4ca2-98be-6c2c1ef961f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n"
     ]
    }
   ],
   "source": [
    "for label, pred in zip(labels, binary_prediction[0]):\n",
    "    if pred == 1:\n",
    "        print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
