{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3098d9e5-b6c4-4d8f-848c-e30f8730183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1593501-9b63-4a8d-80c2-10337666a104",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m       \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mCall signature:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mType:\u001b[0m            _ArrayFunctionDispatcher\n",
       "\u001b[1;31mString form:\u001b[0m     <function expand_dims at 0x0000020C5BEA17E0>\n",
       "\u001b[1;31mFile:\u001b[0m            c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages\\numpy\\lib\\shape_base.py\n",
       "\u001b[1;31mSource:\u001b[0m         \n",
       "\u001b[1;33m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_expand_dims_dispatcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"\n",
       "    Expand the shape of an array.\n",
       "\n",
       "    Insert a new axis that will appear at the `axis` position in the expanded\n",
       "    array shape.\n",
       "\n",
       "    Parameters\n",
       "    ----------\n",
       "    a : array_like\n",
       "        Input array.\n",
       "    axis : int or tuple of ints\n",
       "        Position in the expanded axes where the new axis (or axes) is placed.\n",
       "\n",
       "        .. deprecated:: 1.13.0\n",
       "            Passing an axis where ``axis > a.ndim`` will be treated as\n",
       "            ``axis == a.ndim``, and passing ``axis < -a.ndim - 1`` will\n",
       "            be treated as ``axis == 0``. This behavior is deprecated.\n",
       "\n",
       "        .. versionchanged:: 1.18.0\n",
       "            A tuple of axes is now supported.  Out of range axes as\n",
       "            described above are now forbidden and raise an `AxisError`.\n",
       "\n",
       "    Returns\n",
       "    -------\n",
       "    result : ndarray\n",
       "        View of `a` with the number of dimensions increased.\n",
       "\n",
       "    See Also\n",
       "    --------\n",
       "    squeeze : The inverse operation, removing singleton dimensions\n",
       "    reshape : Insert, remove, and combine dimensions, and resize existing ones\n",
       "    doc.indexing, atleast_1d, atleast_2d, atleast_3d\n",
       "\n",
       "    Examples\n",
       "    --------\n",
       "    >>> x = np.array([1, 2])\n",
       "    >>> x.shape\n",
       "    (2,)\n",
       "\n",
       "    The following is equivalent to ``x[np.newaxis, :]`` or ``x[np.newaxis]``:\n",
       "\n",
       "    >>> y = np.expand_dims(x, axis=0)\n",
       "    >>> y\n",
       "    array([[1, 2]])\n",
       "    >>> y.shape\n",
       "    (1, 2)\n",
       "\n",
       "    The following is equivalent to ``x[:, np.newaxis]``:\n",
       "\n",
       "    >>> y = np.expand_dims(x, axis=1)\n",
       "    >>> y\n",
       "    array([[1],\n",
       "           [2]])\n",
       "    >>> y.shape\n",
       "    (2, 1)\n",
       "\n",
       "    ``axis`` may also be a tuple:\n",
       "\n",
       "    >>> y = np.expand_dims(x, axis=(0, 1))\n",
       "    >>> y\n",
       "    array([[[1, 2]]])\n",
       "\n",
       "    >>> y = np.expand_dims(x, axis=(2, 0))\n",
       "    >>> y\n",
       "    array([[[1],\n",
       "            [2]]])\n",
       "\n",
       "    Note that some examples may use ``None`` instead of ``np.newaxis``.  These\n",
       "    are the same objects:\n",
       "\n",
       "    >>> np.newaxis is None\n",
       "    True\n",
       "\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mout_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_ndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshape_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_it\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_ndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mClass docstring:\u001b[0m\n",
       "Class to wrap functions with checks for __array_function__ overrides.\n",
       "\n",
       "All arguments are required, and can only be passed by position.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "dispatcher : function or None\n",
       "    The dispatcher function that returns a single sequence-like object\n",
       "    of all arguments relevant.  It must have the same signature (except\n",
       "    the default values) as the actual implementation.\n",
       "    If ``None``, this is a ``like=`` dispatcher and the\n",
       "    ``_ArrayFunctionDispatcher`` must be called with ``like`` as the\n",
       "    first (additional and positional) argument.\n",
       "implementation : function\n",
       "    Function that implements the operation on NumPy arrays without\n",
       "    overrides.  Arguments passed calling the ``_ArrayFunctionDispatcher``\n",
       "    will be forwarded to this (and the ``dispatcher``) as if using\n",
       "    ``*args, **kwargs``.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "_implementation : function\n",
       "    The original implementation passed in."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.expand_dims??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ff5019-bc64-4b2e-af0e-f05d54e75a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel python 3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64cb49b4-922f-472e-9101-32961d71640b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e3c361-e520-498a-887b-13570e3ad31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fd5b1d-babd-494c-9356-e3628bef3e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7a7060-8235-4615-870d-307b65837002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\r\\nMore\\r\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\r\\n\\r\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afa6652f-f064-4aa6-b69a-2e70e6a908a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "Name: 3, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70c577-c87a-4dfe-bd12-92f8f6e9a5cb",
   "metadata": {},
   "source": [
    "# 1. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f016b7c-91c4-4d60-8bca-cf6fa7db9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization #tokenization|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f767c49-7bc9-4f52-906c-921e8a53d1b6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mTextVectorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstandardize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower_and_strip_punctuation'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'whitespace'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mngrams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_sequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpad_to_max_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0midf_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mragged\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;33m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"keras.layers.TextVectorization\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"keras.layers.experimental.preprocessing.TextVectorization\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mv1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[0mTextVectorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocessingLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"A preprocessing layer which maps text features to integer sequences.\n",
       "\n",
       "    This layer has basic options for managing text in a Keras model. It\n",
       "    transforms a batch of strings (one example = one string) into either a list\n",
       "    of token indices (one example = 1D tensor of integer token indices) or a\n",
       "    dense representation (one example = 1D tensor of float values representing\n",
       "    data about the example's tokens). This layer is meant to handle natural\n",
       "    language inputs. To handle simple string inputs (categorical strings or\n",
       "    pre-tokenized strings) see `tf.keras.layers.StringLookup`.\n",
       "\n",
       "    The vocabulary for the layer must be either supplied on construction or\n",
       "    learned via `adapt()`. When this layer is adapted, it will analyze the\n",
       "    dataset, determine the frequency of individual string values, and create a\n",
       "    vocabulary from them. This vocabulary can have unlimited size or be capped,\n",
       "    depending on the configuration options for this layer; if there are more\n",
       "    unique values in the input than the maximum vocabulary size, the most\n",
       "    frequent terms will be used to create the vocabulary.\n",
       "\n",
       "    The processing of each example contains the following steps:\n",
       "\n",
       "    1. Standardize each example (usually lowercasing + punctuation stripping)\n",
       "    2. Split each example into substrings (usually words)\n",
       "    3. Recombine substrings into tokens (usually ngrams)\n",
       "    4. Index tokens (associate a unique int value with each token)\n",
       "    5. Transform each example using this index, either into a vector of ints or\n",
       "       a dense float vector.\n",
       "\n",
       "    Some notes on passing callables to customize splitting and normalization for\n",
       "    this layer:\n",
       "\n",
       "    1. Any callable can be passed to this Layer, but if you want to serialize\n",
       "       this object you should only pass functions that are registered Keras\n",
       "       serializables (see `tf.keras.utils.register_keras_serializable` for more\n",
       "       details).\n",
       "    2. When using a custom callable for `standardize`, the data received\n",
       "       by the callable will be exactly as passed to this layer. The callable\n",
       "       should return a tensor of the same shape as the input.\n",
       "    3. When using a custom callable for `split`, the data received by the\n",
       "       callable will have the 1st dimension squeezed out - instead of\n",
       "       `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n",
       "       see `[\"string to split\", \"another string to split\"]`. The callable should\n",
       "       return a Tensor with the first dimension containing the split tokens -\n",
       "       in this example, we should see something like `[[\"string\", \"to\",\n",
       "       \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n",
       "       site natively compatible with `tf.strings.split()`.\n",
       "\n",
       "    For an overview and full list of preprocessing layers, see the preprocessing\n",
       "    [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
       "\n",
       "    Args:\n",
       "      max_tokens: Maximum size of the vocabulary for this layer. This should\n",
       "        only be specified when adapting a vocabulary or when setting\n",
       "        `pad_to_max_tokens=True`. Note that this vocabulary\n",
       "        contains 1 OOV token, so the effective number of tokens is\n",
       "        `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`.\n",
       "      standardize: Optional specification for standardization to apply to the\n",
       "        input text. Values can be:\n",
       "          - `None`: No standardization.\n",
       "          - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all\n",
       "            punctuation removed.\n",
       "          - `\"lower\"`: Text will be lowercased.\n",
       "          - `\"strip_punctuation\"`: All punctuation will be removed.\n",
       "          - Callable: Inputs will passed to the callable function, which should\n",
       "            standardized and returned.\n",
       "      split: Optional specification for splitting the input text. Values can be:\n",
       "          - `None`: No splitting.\n",
       "          - `\"whitespace\"`: Split on whitespace.\n",
       "          - `\"character\"`: Split on each unicode character.\n",
       "          - Callable: Standardized inputs will passed to the callable function,\n",
       "            which should split and returned.\n",
       "      ngrams: Optional specification for ngrams to create from the\n",
       "        possibly-split input text. Values can be None, an integer or tuple of\n",
       "        integers; passing an integer will create ngrams up to that integer, and\n",
       "        passing a tuple of integers will create ngrams for the specified values\n",
       "        in the tuple. Passing None means that no ngrams will be created.\n",
       "      output_mode: Optional specification for the output of the layer. Values\n",
       "        can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the\n",
       "        layer as follows:\n",
       "          - `\"int\"`: Outputs integer indices, one integer index per split string\n",
       "            token. When `output_mode == \"int\"`, 0 is reserved for masked\n",
       "            locations; this reduces the vocab size to\n",
       "            `max_tokens - 2` instead of `max_tokens - 1`.\n",
       "          - `\"multi_hot\"`: Outputs a single int array per batch, of either\n",
       "            vocab_size or max_tokens size, containing 1s in all elements where\n",
       "            the token mapped to that index exists at least once in the batch\n",
       "            item.\n",
       "          - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n",
       "            the number of times the token at that index appeared in the\n",
       "            batch item.\n",
       "          - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied\n",
       "            to find the value in each token slot.\n",
       "        For `\"int\"` output, any shape of input and output is supported. For all\n",
       "        other output modes, currently only rank 1 inputs (and rank 2 outputs\n",
       "        after splitting) are supported.\n",
       "      output_sequence_length: Only valid in INT mode. If set, the output will\n",
       "        have its time dimension padded or truncated to exactly\n",
       "        `output_sequence_length` values, resulting in a tensor of shape\n",
       "        `(batch_size, output_sequence_length)` regardless of how many tokens\n",
       "        resulted from the splitting step. Defaults to None.\n",
       "      pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\n",
       "        modes. If True, the output will have its feature axis padded to\n",
       "        `max_tokens` even if the number of unique tokens in the vocabulary is\n",
       "        less than max_tokens, resulting in a tensor of shape `(batch_size,\n",
       "        max_tokens)` regardless of vocabulary size. Defaults to False.\n",
       "      vocabulary: Optional. Either an array of strings or a string path to a\n",
       "        text file. If passing an array, can pass a tuple, list, 1D numpy array,\n",
       "        or 1D tensor containing the string vocbulary terms. If passing a file\n",
       "        path, the file should contain one line per term in the vocabulary. If\n",
       "        this argument is set, there is no need to `adapt()` the layer.\n",
       "      idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list,\n",
       "        1D numpy array, or 1D tensor or the same length as the vocabulary,\n",
       "        containing the floating point inverse document frequency weights, which\n",
       "        will be multiplied by per sample term counts for the final `tf_idf`\n",
       "        weight. If the `vocabulary` argument is set, and `output_mode` is\n",
       "        `\"tf_idf\"`, this argument must be supplied.\n",
       "      ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns\n",
       "        a `RaggedTensor` instead of a dense `Tensor`, where each sequence may\n",
       "        have a different length after string splitting. Defaults to False.\n",
       "      sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n",
       "        `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n",
       "        dense `Tensor`. Defaults to False.\n",
       "\n",
       "    Example:\n",
       "\n",
       "    This example instantiates a `TextVectorization` layer that lowercases text,\n",
       "    splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
       "\n",
       "    >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
       "    >>> max_features = 5000  # Maximum vocab size.\n",
       "    >>> max_len = 4  # Sequence length to pad the outputs to.\n",
       "    >>>\n",
       "    >>> # Create the layer.\n",
       "    >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
       "    ...  max_tokens=max_features,\n",
       "    ...  output_mode='int',\n",
       "    ...  output_sequence_length=max_len)\n",
       "    >>>\n",
       "    >>> # Now that the vocab layer has been created, call `adapt` on the\n",
       "    >>> # text-only dataset to create the vocabulary. You don't have to batch,\n",
       "    >>> # but for large datasets this means we're not keeping spare copies of\n",
       "    >>> # the dataset.\n",
       "    >>> vectorize_layer.adapt(text_dataset.batch(64))\n",
       "    >>>\n",
       "    >>> # Create the model that uses the vectorize text layer\n",
       "    >>> model = tf.keras.models.Sequential()\n",
       "    >>>\n",
       "    >>> # Start by creating an explicit input layer. It needs to have a shape of\n",
       "    >>> # (1,) (because we need to guarantee that there is exactly one string\n",
       "    >>> # input per batch), and the dtype needs to be 'string'.\n",
       "    >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
       "    >>>\n",
       "    >>> # The first layer in our model is the vectorization layer. After this\n",
       "    >>> # layer, we have a tensor of shape (batch_size, max_len) containing\n",
       "    >>> # vocab indices.\n",
       "    >>> model.add(vectorize_layer)\n",
       "    >>>\n",
       "    >>> # Now, the model can map strings to integers, and you can add an\n",
       "    >>> # embedding layer to map these integers to learned embeddings.\n",
       "    >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
       "    >>> model.predict(input_data)\n",
       "    array([[2, 1, 4, 0],\n",
       "           [1, 3, 0, 0]])\n",
       "\n",
       "    Example:\n",
       "\n",
       "    This example instantiates a `TextVectorization` layer by passing a list\n",
       "    of vocabulary terms to the layer's `__init__()` method.\n",
       "\n",
       "    >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n",
       "    >>> max_len = 4  # Sequence length to pad the outputs to.\n",
       "    >>>\n",
       "    >>> # Create the layer, passing the vocab directly. You can also pass the\n",
       "    >>> # vocabulary arg a path to a file containing one vocabulary word per\n",
       "    >>> # line.\n",
       "    >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
       "    ...  max_tokens=max_features,\n",
       "    ...  output_mode='int',\n",
       "    ...  output_sequence_length=max_len,\n",
       "    ...  vocabulary=vocab_data)\n",
       "    >>>\n",
       "    >>> # Because we've passed the vocabulary directly, we don't need to adapt\n",
       "    >>> # the layer - the vocabulary is already set. The vocabulary contains the\n",
       "    >>> # padding token ('') and OOV token ('[UNK]') as well as the passed\n",
       "    >>> # tokens.\n",
       "    >>> vectorize_layer.get_vocabulary()\n",
       "    ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n",
       "\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mstandardize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lower_and_strip_punctuation\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"whitespace\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mngrams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moutput_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moutput_sequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpad_to_max_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0midf_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mragged\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# This layer only applies to string processing, and so should only have\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# a dtype of 'string'.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`TextVectorization` may only have a dtype of string. \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"Received dtype: {kwargs['dtype']}.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melif\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# 'standardize' must be one of\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# (None, LOWER_AND_STRIP_PUNCTUATION, LOWER, STRIP_PUNCTUATION,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# callable)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlayer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mstandardize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallowable_strings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mLOWER\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mSTRIP_PUNCTUATION\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlayer_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"TextVectorization\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0marg_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"standardize\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallow_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallow_callables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# 'split' must be one of (None, WHITESPACE, CHARACTER, callable)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlayer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallowable_strings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWHITESPACE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHARACTER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlayer_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"TextVectorization\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0marg_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"split\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallow_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallow_callables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Support deprecated names for output_modes.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0moutput_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMULTI_HOT\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tf-idf\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0moutput_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTF_IDF\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# 'output_mode' must be one of (None, INT, COUNT, MULTI_HOT, TF_IDF)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlayer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallowable_strings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOUNT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMULTI_HOT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTF_IDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlayer_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"TextVectorization\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0marg_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"output_mode\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mallow_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# 'ngrams' must be one of (None, int, tuple(int))\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`ngrams` must be None, an integer, or a tuple of \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"integers. Received: ngrams={ngrams}\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# 'output_sequence_length' must be one of (None, int) and is only\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# set if output_mode is INT.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mINT\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_sequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_sequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`output_sequence_length` must be either None or an \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"integer when `output_mode` is 'int'. Received: \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"output_sequence_length={output_sequence_length}\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mINT\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutput_sequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`output_sequence_length` must not be set if `output_mode` is \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"not 'int'. \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"Received output_sequence_length={output_sequence_length}.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mragged\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mINT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`ragged` must not be true if `output_mode` is \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`'int'`. Received: ragged={ragged} and \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"output_mode={output_mode}\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mragged\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moutput_sequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"`output_sequence_length` must not be set if ragged \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"is True. Received: ragged={ragged} and \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34mf\"output_sequence_length={output_sequence_length}\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ngrams_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngrams\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ragged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mragged\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_sequence_length\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# VocabularySavedModelSaver will clear the config vocabulary to restore\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# the lookup table ops directly. We persist this hidden option to\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# persist the fact that we have have a non-adaptable layer with a\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# manually set vocab.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_input_vocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"has_input_vocabulary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Drop deprecated config options.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vocabulary_size\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mbase_preprocessing_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_kpl_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"TextVectorization\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring_lookup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringLookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0midf_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpad_to_max_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmask_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0moutput_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_mode\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mINT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mhas_input_vocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_input_vocabulary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mINT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m[\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moutput_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mINT\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# We override this method solely to generate a docstring.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Computes a vocabulary of string terms from tokens in a dataset.\n",
       "\n",
       "        Calling `adapt()` on a `TextVectorization` layer is an alternative to\n",
       "        passing in a precomputed vocabulary on construction via the `vocabulary`\n",
       "        argument. A `TextVectorization` layer should always be either adapted\n",
       "        over a dataset or supplied with a vocabulary.\n",
       "\n",
       "        During `adapt()`, the layer will build a vocabulary of all string tokens\n",
       "        seen in the dataset, sorted by occurrence count, with ties broken by\n",
       "        sort order of the tokens (high to low). At the end of `adapt()`, if\n",
       "        `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\n",
       "        size. For example, adapting a layer with `max_tokens=1000` will compute\n",
       "        the 1000 most frequent tokens occurring in the input dataset. If\n",
       "        `output_mode='tf-idf'`, `adapt()` will also learn the document\n",
       "        frequencies of each token in the input dataset.\n",
       "\n",
       "        In order to make `TextVectorization` efficient in any distribution\n",
       "        context, the vocabulary is kept static with respect to any compiled\n",
       "        `tf.Graph`s that call the layer. As a consequence, if the layer is\n",
       "        adapted a second time, any models using the layer should be re-compiled.\n",
       "        For more information see\n",
       "        `tf.keras.layers.experimental.preprocessing.PreprocessingLayer.adapt`.\n",
       "\n",
       "        `adapt()` is meant only as a single machine utility to compute layer\n",
       "        state.  To analyze a dataset that cannot fit on a single machine, see\n",
       "        [Tensorflow Transform](\n",
       "        https://www.tensorflow.org/tfx/transform/get_started) for a\n",
       "        multi-machine, map-reduce solution.\n",
       "\n",
       "        Arguments:\n",
       "          data: The data to train on. It can be passed either as a\n",
       "              `tf.data.Dataset`, or as a numpy array.\n",
       "          batch_size: Integer or `None`.\n",
       "              Number of samples per state update.\n",
       "              If unspecified, `batch_size` will default to 32.\n",
       "              Do not specify the `batch_size` if your data is in the\n",
       "              form of datasets, generators, or `keras.utils.Sequence` instances\n",
       "              (since they generate batches).\n",
       "          steps: Integer or `None`.\n",
       "              Total number of steps (batches of samples)\n",
       "              When training with input tensors such as\n",
       "              TensorFlow data tensors, the default `None` is equal to\n",
       "              the number of samples in your dataset divided by\n",
       "              the batch size, or 1 if that cannot be determined. If x is a\n",
       "              `tf.data` dataset, and 'steps' is None, the epoch will run until\n",
       "              the input dataset is exhausted. When passing an infinitely\n",
       "              repeating dataset, you must specify the `steps` argument. This\n",
       "              argument is not supported with array inputs.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfinalize_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Returns the current vocabulary of the layer.\n",
       "\n",
       "        Args:\n",
       "          include_special_tokens: If True, the returned vocabulary will include\n",
       "            the padding and OOV tokens, and a term's index in the vocabulary\n",
       "            will equal the term's index when calling the layer. If False, the\n",
       "            returned vocabulary will not include any padding or OOV tokens.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_special_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Gets the current size of the layer's vocabulary.\n",
       "\n",
       "        Returns:\n",
       "          The integer size of the vocabulary, including optional mask and\n",
       "          OOV indices.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_vocabulary\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0midf_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_idf_weights\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"max_tokens\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"standardize\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"ngrams\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ngrams_arg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"output_mode\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"output_sequence_length\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"pad_to_max_tokens\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"sparse\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"ragged\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ragged\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"vocabulary\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistify_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;34m\"idf_weights\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistify_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mbase_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mset_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Sets vocabulary (and optionally document frequency) data for this layer.\n",
       "\n",
       "        This method sets the vocabulary and idf weights for this layer directly,\n",
       "        instead of analyzing a dataset through 'adapt'. It should be used\n",
       "        whenever the vocab (and optionally document frequency) information is\n",
       "        already known.  If vocabulary data is already present in the layer, this\n",
       "        method will replace it.\n",
       "\n",
       "        Args:\n",
       "          vocabulary: Either an array or a string path to a text file. If\n",
       "            passing an array, can pass a tuple, list, 1D numpy array, or 1D\n",
       "            tensor containing the vocbulary terms. If passing a file path, the\n",
       "            file should contain one line per term in the vocabulary.\n",
       "          idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse\n",
       "            document frequency weights with equal length to vocabulary. Must be\n",
       "            set if `output_mode` is `\"tf_idf\"`. Should not be set otherwise.\n",
       "\n",
       "        Raises:\n",
       "          ValueError: If there are too many inputs, the inputs do not match, or\n",
       "            input data is missing.\n",
       "          RuntimeError: If the vocabulary cannot be set when this function is\n",
       "            called. This happens when `\"multi_hot\"`, `\"count\"`, and \"tf_idf\"\n",
       "            modes, if `pad_to_max_tokens` is False and the layer itself has\n",
       "            already been called.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLOWER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mSTRIP_PUNCTUATION\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregex_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEFAULT_STRIP_REGEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# If we are splitting, we validate that the 1st axis is of dimension\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# 1 and so can be squeezed out. We do this here instead of after\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# splitting for performance reasons - it's more expensive to squeeze\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# a ragged tensor.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"When using `TextVectorization` to tokenize strings, \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"the input rank must be 1 or the last shape dimension \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34mf\"must be 1. Received: inputs.shape={inputs.shape} \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34mf\"with rank={inputs.shape.rank}\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWHITESPACE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# This treats multiple whitespaces as one whitespace, and strips\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# leading and trailing whitespace.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mCHARACTER\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0municode_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"%s is not a supported splitting.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"TextVectorization supports the following options \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"for `split`: None, 'whitespace', or a Callable.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Note that 'inputs' here can be either ragged or dense depending on the\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# configuration choices for this Layer. The strings.ngrams op, however,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# does support both ragged and dense inputs.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ngrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# If we're not doing any output processing, return right away.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlookup_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# For any non-int output, we can return directly from the underlying\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# layer.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mINT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ragged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# If we have a ragged tensor, we can pad during the conversion to dense.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ragged\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# If output sequence length is None, to_tensor will pad the last\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# dimension to the bounding shape of the ragged dimension.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# If we have a dense tensor, we need to pad/trim directly.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Maybe trim the output.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlookup_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Maybe pad the output. We need to be careful to use dynamic shape\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# here as required_space_to_batch_paddings requires a fully known\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# shape.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpadded_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequired_space_to_batch_paddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded_shape\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_trackable_saved_model_saver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_serialization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVocabularySavedModelSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TextVectorization??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af1d68cc-4363-47b5-a06e-f7f058684a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d81f44c-ea65-4de0-a272-4bfaf4cc8c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e86c249d-955a-402d-97da-ab49ba375ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\r\\nWhy the edits made under my use...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\r\\n\\r\\nThat...\n",
       "159568    Spitzer \\r\\n\\r\\nUmm, theres no actual article ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\r\\nAnd ... I really don't think you understa...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aaed8ae-5db8-4ed9-8a5f-feb0cc8e98c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a87be30c-3f7c-4bd8-8355-fb564090e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 #number of words in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19a4be54-99a8-4c89-88be-83516435a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
    "                              output_sequence_length=1800,\n",
    "                              output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff5db367-a9ab-44a7-b029-0a9cc08f5810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\r\\nWhy the edits made under my use...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\r\\n\\r\\nThat...\n",
       "159568    Spitzer \\r\\n\\r\\nUmm, theres no actual article ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\r\\nAnd ... I really don't think you understa...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97bd949b-bbca-4b7c-a59a-ee0c3c55ca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39b05787-2deb-4a83-9471-e8cecdd7b9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Explanation\\r\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
       "       ...,\n",
       "       'Spitzer \\r\\n\\r\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.',\n",
       "       'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.',\n",
       "       '\"\\r\\nAnd ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values #mengubah X pandas series ke numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de24527a-e0db-4132-9bf2-c669e7911ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65a98b55-4320-4906-b59d-83acc1b06bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1800,), dtype=int64, numpy=array([ 286, 4763,    0, ...,    0,    0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer('Hello Bang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67734dcf-3bea-422a-a39c-6c6eb656d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f468ecd3-6362-49e7-b6fe-4de4298e2fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  643,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2506, ...,     0,     0,     0],\n",
       "       [  425,   440,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32141,  7329,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   533, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text = vectorizer(X.values)\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2c23991-86b6-4d8b-b5c5-7952237f26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCSHBAP -- map, cache, shuffle, batch, prefetch from_tensor_slices, list_file\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "906ebec3-02fb-4c7e-a38a-7186e3d21804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1581, 1574,   40, ...,    0,    0,    0],\n",
       "        [  23,  244,    9, ...,    0,    0,    0],\n",
       "        [1857,    5,  302, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   7, 2486,   30, ...,    0,    0,    0],\n",
       "        [ 170,  122,    8, ...,    0,    0,    0],\n",
       "        [   8,   74,  239, ...,    0,    0,    0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed9b6a10-2407-40bd-8cbb-63ad69b8be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5af4cd15-b9f1-4847-b31f-584f552b625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran Batch X (16, 1800)\n",
      "Ukuran Batch y (16, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Ukuran Batch X', batch_X.shape)\n",
    "print('Ukuran Batch y', batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e64b8d88-e9af-44e4-8af1-8b43d6ac1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset)*16 jml total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68d346b8-f37c-4b27-bf1d-29ce8e47bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7)) # 70% dari len dataset\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc9a7bc8-f530-455f-b6e5-0664a5437ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumal data train 6981\n",
      "Jumal data val 1994\n",
      "Jumal data test 997\n"
     ]
    }
   ],
   "source": [
    "print('Jumal data train', len(train))\n",
    "print('Jumal data val', len(val))\n",
    "print('Jumal data test', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9ad1e46-2355-48aa-bf5e-d37a80a6bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c70fda6-5730-4a5d-8005-d35fe1900027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 265,   10,   25, ...,    0,    0,    0],\n",
       "        [   7,  677,    4, ...,    0,    0,    0],\n",
       "        [ 124,    7, 9346, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [  70,   15,  164, ...,    0,    0,    0],\n",
       "        [ 265,   35,   10, ...,    0,    0,    0],\n",
       "        [  48,  352,   10, ...,    0,    0,    0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d293ba7-bbea-478a-ba37-d464cdf15be2",
   "metadata": {},
   "source": [
    "# 2. Create Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34632f6a-c039-4a0d-9a74-dda53c3c18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3132733c-2216-4741-91a7-7897c0300c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#create embedding layers\n",
    "model.add(Embedding(MAX_FEATURES +1, 32))\n",
    "\n",
    "# #Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "# model.add(LSTM(32, activation='tanh'))\n",
    "\n",
    "#Feature extractor fully\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(6, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20e110c7-4604-486e-81e1-b67be372916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59b66973-478a-4e6b-9b5d-66b26484688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb6678-0191-4723-ab7e-a3fc29205b33",
   "metadata": {},
   "source": [
    "disaranin epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcf36b93-d18e-4e11-9084-393a62c7e4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6981/6981 [==============================] - 2204s 314ms/step - loss: 0.0617 - val_loss: 0.0449\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=1, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "810500f9-006b-478e-a44d-e02fa28b4884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.06167217344045639], 'val_loss': [0.04491858556866646]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "545d64bd-87ff-4bb0-8e98-06c9ecdfd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18aa5549-4c31-4e7f-bde1-87d0ea91955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bc656-4837-4bf3-9e4c-efadcb860c0a",
   "metadata": {},
   "source": [
    "# 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b816e86c-5d34-4ffd-9440-84ef0b1ad215",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorizer('You freaking suck! i will to kill you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35fabfdd-a0a2-4d42-90b6-de6750b7d968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91fdd8fc-f8c1-4ce9-acff-11a14e87979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 495ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99439526, 0.3512241 , 0.94991744, 0.07631917, 0.7939208 ,\n",
       "        0.20017867]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(np.array([input_text]))\n",
    "model.predict(np.expand_dims(input_text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "35a07d6b-40f4-4da2-8d18-f7f90054718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "057c2183-914f-4a78-a895-d98bacf9d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "924e623d-fbb1-4ffb-ba41-360ae37d805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 490ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c7315bd5-b671-4b2c-9eca-d79e7c00b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 468ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_text, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729f8db-453f-44f4-b6b9-fccc93d9021c",
   "metadata": {},
   "source": [
    "# 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "20d105f1-cd16-4bcc-8500-8ae37db6490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f9431982-0b91-4734-bc72-c4ef4e8685ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f159b14c-9ac3-4828-bbde-8bc96921f332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    #unpack batch\n",
    "    X_true, y_true = batch\n",
    "\n",
    "    #make prediction\n",
    "    yhat = model.predict(X_true)\n",
    "\n",
    "    #flatten the prediction\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "\n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3fd997af-615a-4fa8-961b-66e41eee8714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7868520021438599, Recall:0.7627737522125244, Accuracy:0.4814443290233612\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5767d6-5f0c-49e4-9662-29449835793b",
   "metadata": {},
   "source": [
    "# 5. Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "94023952-9110-47e0-a6cd-13fd82889a09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.31.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.16.2 (from gradio)\n",
      "  Downloading gradio_client-0.16.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.3-cp310-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.9/50.9 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "     ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 107.3/107.3 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.4.4-py3-none-win_amd64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fsspec (from gradio-client==0.16.2->gradio)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.2->gradio)\n",
      "  Downloading websockets-11.0.3-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting anyio (from httpx>=0.24.1->gradio)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
      "Collecting sniffio (from httpx>=0.24.1->gradio)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.18.2-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
      "  Downloading fastapi_cli-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
      "  Downloading ujson-5.9.0-cp310-cp310-win_amd64.whl.metadata (8.9 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading rpds_py-0.18.1-cp310-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading watchfiles-0.21.0-cp310-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\.conda\\envs\\py310\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.31.0-py3-none-any.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.3 MB 2.8 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.2/12.3 MB 2.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/12.3 MB 2.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/12.3 MB 3.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.3 MB 3.2 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.8/12.3 MB 3.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/12.3 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/12.3 MB 3.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.4/12.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/12.3 MB 3.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/12.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.2/12.3 MB 3.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.3 MB 4.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.7/12.3 MB 4.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.3 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.1/12.3 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.3/12.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.6/12.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/12.3 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.0/12.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.3 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.4/12.3 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.6/12.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.9/12.3 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.1/12.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.4/12.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.6/12.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.3 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.1/12.3 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.3 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.6/12.3 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.0/12.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.2/12.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.4/12.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.7/12.3 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.0/12.3 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.4/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.0/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.5/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.7/12.3 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.3 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.3/12.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.3 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.16.2-py3-none-any.whl (315 kB)\n",
      "   ---------------------------------------- 0.0/315.5 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 204.8/315.5 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 315.5/315.5 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "   ---------------------------------------- 0.0/857.8 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 204.8/857.8 kB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 501.8/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 706.6/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 706.6/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 706.6/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 706.6/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 706.6/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 706.6/857.8 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 857.8/857.8 kB 2.4 MB/s eta 0:00:00\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 194.6/401.2 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/401.2 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.2/401.2 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.3-cp310-none-win_amd64.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.8/138.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 409.3/409.3 kB 26.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.2-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.9 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.9/1.9 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/1.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl (145 kB)\n",
      "   ---------------------------------------- 0.0/145.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 145.3/145.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading ruff-0.4.4-py3-none-win_amd64.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.4 MB 6.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/8.4 MB 7.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/8.4 MB 6.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/8.4 MB 6.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.4 MB 6.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.6/8.4 MB 6.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.4 MB 6.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.0/8.4 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.3/8.4 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.6/8.4 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.7/8.4 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.0/8.4 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.3/8.4 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.4/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.6/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.9/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.1/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.3/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.5/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.8/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.1/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.4/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.6/8.4 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.9/8.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.1/8.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.3/8.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.4/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.6/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.9/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.2/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.4/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.6/8.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.9/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.0/8.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.3/8.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 92.0/92.0 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/172.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 172.0/172.0 kB 5.2 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 4.1 MB/s eta 0:00:00\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading ujson-5.9.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.9/41.9 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp310-cp310-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.7/124.7 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB 3.1 MB/s eta 0:00:00\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 256.0/307.7 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 307.7/307.7 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp310-cp310-win_amd64.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.2/58.2 kB 3.0 MB/s eta 0:00:00\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.1-cp310-none-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.0/209.0 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.21.0-cp310-none-win_amd64.whl (279 kB)\n",
      "   ---------------------------------------- 0.0/279.7 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 225.3/279.7 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 279.7/279.7 kB 4.3 MB/s eta 0:00:00\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5607 sha256=a68fbe132cef81d07aac5392a0bdddec401c4f8ffa4f8e5b2fce632cf560ef8d\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\bd\\65\\9a\\671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, ujson, tqdm, toolz, tomlkit, sniffio, shellingham, semantic-version, ruff, rpds-py, pyyaml, python-multipart, python-dotenv, pydantic-core, orjson, mdurl, jinja2, importlib-resources, httptools, h11, fsspec, filelock, dnspython, click, attrs, annotated-types, aiofiles, uvicorn, referencing, pydantic, markdown-it-py, huggingface-hub, httpcore, email_validator, anyio, watchfiles, starlette, rich, jsonschema-specifications, httpx, typer, jsonschema, gradio-client, altair, fastapi-cli, fastapi, gradio\n",
      "Successfully installed aiofiles-23.2.1 altair-5.3.0 annotated-types-0.6.0 anyio-4.3.0 attrs-23.2.0 click-8.1.7 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 ffmpy-0.3.2 filelock-3.14.0 fsspec-2024.3.1 gradio-4.31.0 gradio-client-0.16.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.0 importlib-resources-6.4.0 jinja2-3.1.4 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.3 pydantic-2.7.1 pydantic-core-2.18.2 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 pyyaml-6.0.1 referencing-0.35.1 rich-13.7.1 rpds-py-0.18.1 ruff-0.4.4 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 tqdm-4.66.4 typer-0.12.3 ujson-5.9.0 uvicorn-0.29.0 watchfiles-0.21.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "649edd2d-755f-48da-8e50-774ddc1701fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4cc08314-b7a3-41c9-8eeb-ffedd60d76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1299682f-cd4d-4edc-b421-b0fb1d1013bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "82a3b714-7ebd-4c09-9390-90f27be4c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer('you are ugly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3041032d-57e8-4994-9874-ef2c3139f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "baf6d462-8176-4c48-885a-48f4e4d1aa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90842664, 0.04118547, 0.6266571 , 0.03426718, 0.5350182 ,\n",
       "        0.07258698]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2e20a4ce-df3a-48fe-9dda-f6f04b253255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    result = model.predict(vectorized_comment)\n",
    "\n",
    "    # print kelas klasifikasinya\n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, result[0][idx]>0.5)  # Changed results to result\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "753e235c-1d19-45e4-bb41-8f1deb823d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn=score_comment,\n",
    "                         inputs=gr.Textbox(lines=2, placeholder='Comment to score'),\n",
    "                         outputs='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d988f-ee6a-4f2f-b524-45fa07f8897a",
   "metadata": {},
   "source": [
    "harus matiin antivirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77585899-e715-477c-b165-cde3eea4e71d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://59dfb9b1d3c665e0f6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://59dfb9b1d3c665e0f6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 535ms/step\n"
     ]
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e28f0-3402-42fe-a322-96ae9776228a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
